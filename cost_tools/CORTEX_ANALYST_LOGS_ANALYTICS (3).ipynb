{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7mqhrkqavgxeoc33f5um",
   "authorId": "735213434345",
   "authorName": "KAITLYN",
   "authorEmail": "kaitlyn.wells@snowflake.com",
   "sessionId": "c4c323b1-d41a-4a73-aba9-8637c3cb6961",
   "lastEditTime": 1756313117804
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "session_imports"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "fetch_agents"
   },
   "source": "agents_df = session.sql(\"SHOW AGENTS IN SCHEMA snowflake_intelligence.agents\").to_pandas()\nagents_df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fd55fea7-7fb9-4ce6-82e8-a893fded325d",
   "metadata": {
    "language": "python",
    "name": "helper_functions"
   },
   "outputs": [],
   "source": "def fetch_semantic_model_paths(session):\n    results = []\n    agent_names = agents_df[1].tolist()\n    \n    for agent in agent_names:\n        describe_sql = f'DESCRIBE AGENT SNOWFLAKE_INTELLIGENCE.AGENTS.\"{agent}\"'\n        df_desc = session.sql(describe_sql).to_pandas()\n         # Each DESCRIBE returns an 'AGENT_SPEC' column as a JSON string\n        \n        agent_spec_json = df_desc[6].iloc[0]\n            \n        if agent_spec_json:\n            try:\n                import json\n                spec = json.loads(agent_spec_json)\n                \n                if 'tool_resources' in spec:\n                    for tool_name, tool_data in spec['tool_resources'].items():\n                        semantic_file = tool_data.get('semantic_model_file')\n                        results.append({\n                            \"agent_name\": agent,\n                            \"tool_name\": tool_name,\n                            \"semantic_model_file\": semantic_file\n                        })\n            except json.JSONDecodeError:\n                pass\n        \n    # Convert to DataFrame for display\n    df_results = pd.DataFrame(results)\n    return df_results\n\ndef get_cortex_analyst_logs(SEMANTIC_MODEL_FILE):\n    cortex_analyst_log = session.sql(f'''SELECT \n          timestamp,\n          request_id,\n          semantic_model_name,\n          tables_referenced,\n          user_name,\n          source,\n          feedback,\n          response_status_code,\n          request_body:messages[0].content[0].text::STRING as user_question,\n          response_body:response_metadata.analyst_latency_ms::NUMBER as latency_ms,\n          generated_sql,\n          response_body:response_metadata.analyst_orchestration_path::STRING as orchestration_path,\n          response_body:response_metadata.question_category::STRING as question_category,\n          response_body:message.content[1].confidence.verified_query_used.name::STRING as verified_query_name,\n         response_body:message.content[1].confidence.verified_query_used.question::STRING as verified_query_question\n        FROM TABLE(\n          SNOWFLAKE.LOCAL.CORTEX_ANALYST_REQUESTS('FILE_ON_STAGE', '{SEMANTIC_MODEL_FILE}'))''')\n    \n    df = cortex_analyst_log.to_pandas()\n    df[\"QUERY_TYPE\"] = df[\"ORCHESTRATION_PATH\"].apply(\n    lambda x: \"Verified Query\" if x == \"vqr_fast_path\" else \"Non-Verified Query\"\n)   \n    df['CORTEX_ANALYST_CREDITS'] = 67/1000\n    \n    # Push back into Snowflake (append to table)\n    session.write_pandas(\n        df,\n        table_name=\"CORTEX_ANALYST_LOGS\",\n        database=None,   # or specify your DB\n        schema=None,     # or specify your schema\n        auto_create_table=False,  # you already created the table\n        overwrite=False\n    )\n    return df\n    \ndef verified_query_count(df):\n    # Breakdown by semantic model\n    semantic_model_summary = (\n        df.groupby(['SEMANTIC_MODEL_NAME', 'QUERY_TYPE'])\n        .size()\n        .reset_index(name=\"request_count\")\n    )\n    \n    # Calculate percentages within each semantic model\n    semantic_model_summary[\"percentage\"] = (\n        semantic_model_summary\n        .groupby('SEMANTIC_MODEL_NAME')['request_count']\n        .transform(lambda x: round((x * 100.0) / x.sum(), 2))\n    )\n    \n    # Sort by semantic model and request count\n    semantic_model_summary = semantic_model_summary.sort_values(\n        ['SEMANTIC_MODEL_NAME', 'request_count'], \n        ascending=[True, False]\n    ).reset_index(drop=True)\n    \n    return semantic_model_summary\n\ndef top_verified_queries(df):\n    # Breakdown by semantic model\n    semantic_model_top = (\n        df[df['QUERY_TYPE'] == 'Verified Query']\n        .groupby([\"SEMANTIC_MODEL_NAME\", \"VERIFIED_QUERY_NAME\", \"VERIFIED_QUERY_QUESTION\"])\n        .size()\n        .reset_index(name=\"frequency\")\n    )\n    \n    # Calculate percentages within each semantic model\n    semantic_model_top[\"percentage_of_verified_queries\"] = (\n        semantic_model_top\n        .groupby('SEMANTIC_MODEL_NAME')['frequency']\n        .transform(lambda x: round((x * 100.0) / x.sum(), 2))\n    )\n    \n    # Sort by semantic model and frequency, take top 10 per model\n    semantic_model_top = (\n        semantic_model_top\n        .sort_values(['SEMANTIC_MODEL_NAME', 'frequency'], ascending=[True, False])\n        .groupby('SEMANTIC_MODEL_NAME')\n        .head(10)\n        .reset_index(drop=True)\n    )\n\n    return semantic_model_top\n\ndef slowest_queries(df, number=10):\n    # Filter out rows where latency_ms is null\n    slow_queries = df[df[\"LATENCY_MS\"].notnull()].copy()\n    \n    # Compute latency in seconds\n    slow_queries[\"LATENCY_SECONDS\"] = (slow_queries[\"LATENCY_MS\"] / 1000.0).round(2)\n    \n    # Breakdown by semantic model - top slowest per model\n    semantic_model_slow = slow_queries[[\n        \"SEMANTIC_MODEL_NAME\",\n        \"USER_QUESTION\",\n        \"LATENCY_SECONDS\",\n        \"ORCHESTRATION_PATH\",\n        \"QUESTION_CATEGORY\"\n    ]].sort_values(['SEMANTIC_MODEL_NAME', 'LATENCY_SECONDS'], ascending=[True, False])\n    \n    # Take top N slowest per semantic model\n    semantic_model_slow = (\n        semantic_model_slow\n        .groupby('SEMANTIC_MODEL_NAME')\n        .head(number)\n        .reset_index(drop=True)\n    )\n    \n    return semantic_model_slow\n\ndef latency_summary_by_semantic_model(df):\n    \"\"\"\n    Provides latency statistics breakdown by semantic model.\n    \"\"\"\n    # Filter out rows where latency_ms is null\n    latency_data = df[df[\"LATENCY_MS\"].notnull()].copy()\n    \n    # Compute latency in seconds\n    latency_data[\"LATENCY_SECONDS\"] = (latency_data[\"LATENCY_MS\"] / 1000.0).round(2)\n    \n    # Stats by semantic model\n    semantic_model_stats = (\n        latency_data\n        .groupby('SEMANTIC_MODEL_NAME')['LATENCY_SECONDS']\n        .agg(['count', 'mean', 'median', 'min', 'max'])\n        .round(2)\n        .reset_index()\n    )\n    \n    semantic_model_stats.columns = [\n        'SEMANTIC_MODEL_NAME', 'query_count', 'avg_latency_seconds', \n        'median_latency_seconds', 'min_latency_seconds', 'max_latency_seconds'\n    ]\n    \n    return semantic_model_stats\n\ndef create_sf_intelligence_query_history(session, target_table=\"snowflake_intelligence.public.sf_intelligence_query_history\"):\n    \"\"\"\n    Creates or replaces a table with Cortex Agent query history joined to query attribution.\n    Keeps last 30 days of queries with compute credits > 0 and cleans query text for matching.\n    \n    Parameters\n    ----------\n    session : snowflake.snowpark.Session\n        Active Snowpark session.\n    target_table : str, optional\n        Fully qualified name of the target table.\n    \"\"\"\n    \n    query = f\"\"\"\n    CREATE OR REPLACE TABLE {target_table} AS\n    SELECT \n        qh.query_id,\n        qh.query_text,\n        qh.start_time,\n        qh.total_elapsed_time,\n        qh.warehouse_name,\n        qh.user_name,\n        qah.credits_attributed_compute,\n        -- Clean the generated SQL for matching\n        TRIM(REGEXP_REPLACE(\n            REGEXP_REPLACE(\n                REGEXP_REPLACE(qh.query_text, '--[^\\\\n]*\\\\n', '\\\\n'),\n                '/\\\\*.*?\\\\*/', ' '\n            ),\n            '\\\\s+', ' '\n        )) AS cleaned_query_text\n    FROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY qh\n    JOIN SNOWFLAKE.ACCOUNT_USAGE.QUERY_ATTRIBUTION_HISTORY qah \n        ON qh.query_id = qah.query_id\n    WHERE qh.query_tag = 'cortex-agent'\n      AND qh.start_time >= DATEADD(DAY, -30, CURRENT_TIMESTAMP())\n      AND qah.credits_attributed_compute > 0\n    \"\"\"\n    \n    session.sql(query).collect()\n    print(f\"âœ… Table {target_table} created/updated successfully.\")\n\n    ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e74dab9-fb3a-4934-9de5-ec74f803c6d5",
   "metadata": {
    "language": "python",
    "name": "fetch_semantic_model_files"
   },
   "outputs": [],
   "source": "df_results = fetch_semantic_model_paths(session)\ndf_results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ef85317-8c07-4e4c-9dba-eb4cdcc03eb5",
   "metadata": {
    "language": "sql",
    "name": "create_analyst_logs_table"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE CORTEX_ANALYST_LOGS (\n    TIMESTAMP                TIMESTAMP_NTZ,\n    REQUEST_ID               STRING,\n    SEMANTIC_MODEL_NAME      STRING,\n    TABLES_REFERENCED        STRING,\n    USER_NAME                STRING,\n    SOURCE                   STRING,\n    FEEDBACK                 STRING,\n    RESPONSE_STATUS_CODE     INTEGER,\n    USER_QUESTION            STRING,\n    LATENCY_MS               NUMBER,\n    GENERATED_SQL            STRING,\n    ORCHESTRATION_PATH       STRING,\n    QUESTION_CATEGORY        STRING,\n    VERIFIED_QUERY_NAME      STRING,\n    VERIFIED_QUERY_QUESTION  STRING,\n    QUERY_TYPE               STRING,\n    CORTEX_ANALYST_CREDITS   FLOAT\n);\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82b47aa0-dc50-4dab-9056-dff97a6ae80c",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "test_2 = latency_summary_by_semantic_model(df_agg)\ntest_2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6e338e2-6641-46e2-bdb1-541cac257d6a",
   "metadata": {
    "language": "python",
    "name": "write_all_logs_to_table"
   },
   "outputs": [],
   "source": "for file in df_results['semantic_model_file']:\n    if file != None:\n        df = get_cortex_analyst_logs(file)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34eb8e94-5a49-41df-a499-3d5fc4462591",
   "metadata": {
    "language": "sql",
    "name": "cortex_analyst_logs"
   },
   "outputs": [],
   "source": "select * from CORTEX_ANALYST_LOGS limit 100;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7597b2d0-f061-4688-a90c-8982b2cdda92",
   "metadata": {
    "language": "python",
    "name": "logs_by_semantic_model"
   },
   "outputs": [],
   "source": "# SEMANTIC_MODEL_FILE = '@E2E_SNOW_MLOPS_DB.STREAMLIT.SEMANTIC/mortgage_lending_prediction_v2.yaml'\n\n# df = get_cortex_analyst_logs(SEMANTIC_MODEL_FILE)\n\n# vq_sum_df = verified_query_count(df)\n# top_verified_queries_df = top_verified_queries(df)\n# slowest_queries_df = slowest_queries(df)\n# df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "602aa768-4039-4f5b-a986-84d2a2d656eb",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "print(df.columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f574dbf1-d424-4d86-8f4b-045d86c8875f",
   "metadata": {
    "language": "python",
    "name": "plots"
   },
   "outputs": [],
   "source": "import streamlit as st\n\n# Verified vs Non-Verified Queries\nst.subheader(\"Verified vs Non-Verified Queries\")\nst.dataframe(vq_sum_df)\nst.bar_chart(vq_sum_df.set_index(\"QUERY_TYPE\")[\"request_count\"])\n\n# Top 10 Verified Queries\nst.subheader(\"Top 10 Verified Queries\")\nst.dataframe(top_verified_queries_df)\nst.bar_chart(top_verified_queries_df.set_index(\"VERIFIED_QUERY_QUESTION\")[\"frequency\"])\n\n# Slowest Queries\nst.subheader(\"Top 10 Slowest Queries\")\nst.dataframe(slowest_queries_df)\nst.bar_chart(slowest_queries_df.set_index(\"USER_QUESTION\")[\"LATENCY_SECONDS\"])\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7cefaf8-dd5a-4a4a-88d9-4778f506af73",
   "metadata": {
    "language": "python",
    "name": "create_sf_intelligence_query_history_table"
   },
   "outputs": [],
   "source": "##THIS IS SLOW - ONLY RUN THIS IF YOU HAVEN'T ALREADY\n# create_sf_intelligence_query_history(session)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9af8f143-98a4-44d9-b858-ac8db0431447",
   "metadata": {
    "language": "python",
    "name": "combine_cortex_logs_with_query_history"
   },
   "outputs": [],
   "source": "\nsfi_query_history = session.table(\"snowflake_intelligence.public.sf_intelligence_query_history\")\npd_sfi_query_history = sfi_query_history.to_pandas()\npd_sfi_query_history.set_index(\"CLEANED_QUERY_TEXT\")\ndf.set_index(\"GENERATED_SQL\")\n\n##joining on generated SQL\nca_query_history = pd.merge(pd_sfi_query_history, df, left_index=True, right_index=True)\nca_query_history['TOTAL_TIME'] = ca_query_history[\"TOTAL_ELAPSED_TIME\"] + ca_query_history[\"LATENCY_MS\"]\nca_query_history['TOTAL_CREDITS_WH_AND_CA'] = ca_query_history[\"CREDITS_ATTRIBUTED_COMPUTE\"] + ca_query_history[\"CORTEX_ANALYST_CREDITS\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f3e1059-a1d6-4bc2-9a5a-f24a19210870",
   "metadata": {
    "language": "python",
    "name": "cost_analysis"
   },
   "outputs": [],
   "source": "total_credits_attributed_compute = round(ca_query_history[\"CREDITS_ATTRIBUTED_COMPUTE\"].sum(), 4)\nst.metric(label=\"Total Attributed WH Query Credits\", value=total_credits_attributed_compute)\n\n# Cost analysis\ntotal_cost_by_user = ca_query_history.groupby('USER_NAME_y')['CREDITS_ATTRIBUTED_COMPUTE'].sum()\nst.dataframe(total_cost_by_user)\n\ntotal_cortex_analyst_credits_by_user = ca_query_history.groupby('USER_NAME_y')['TOTAL_CREDITS_WH_AND_CA'].sum()\nst.dataframe(total_cortex_analyst_credits_by_user)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "903fb318-ec53-4ee3-897c-9f972f3befb2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "print(ca_query_history.columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "420d425d-8b60-430b-a022-eb036e9b4f05",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "avg_total_latency_ms = round(ca_query_history['TOTAL_TIME'].mean())\nst.metric(label=\"Average Total Latency (CA + SQL Execution) ms\", value=avg_total_latency_ms)\nca_latency_stats = ca_query_history['LATENCY_MS'].describe()\nst.subheader(\"Cortex Analyst Latency Stats (MS)\")\nst.dataframe(ca_latency_stats)\n\nwh_query_latency_stats = ca_query_history['TOTAL_ELAPSED_TIME'].describe()\nst.subheader(\"SQL Execution WH Latency Stats (MS)\")\nst.dataframe(wh_query_latency_stats)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0f9535b-083e-4a00-b847-6c6a371a82b1",
   "metadata": {
    "language": "python",
    "name": "usage_breakdown"
   },
   "outputs": [],
   "source": "# User adoption and activity\nuser_activity = ca_query_history.groupby('USER_NAME_y').agg({\n    'QUERY_ID': 'count',\n    'LATENCY_MS': 'mean',\n    'CREDITS_ATTRIBUTED_COMPUTE': 'sum'\n}).rename(columns={'QUERY_ID': 'total_queries'})\nst.subheader(\"User Activity\")\nst.dataframe(user_activity)\n\n# Query frequency over time\nca_query_history['date'] = pd.to_datetime(ca_query_history['TIMESTAMP']).dt.date\ndaily_usage = ca_query_history.groupby('date')['QUERY_ID'].count()\n\n\n# Most used semantic models\nmodel_usage = ca_query_history['SEMANTIC_MODEL_NAME'].value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "153a8d50-e463-4c1d-bae0-6e354a1263df",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "SELECT sum FROM SNOWFLAKE.account_usage.CORTEX_ANALYST_USAGE_HISTORY",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dcd097bf-3656-4103-ad18-c35428eb2e11",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "def user_activity_by_semantic_model(df):\n    \"\"\"\n    Provides user activity analysis by semantic model.\n    Returns a DataFrame with user activity broken down by semantic model.\n    \"\"\"\n    import pandas as pd\n    \n    # User activity by semantic model\n    user_model_activity = df.groupby(['USER_NAME', 'SEMANTIC_MODEL_NAME']).agg({\n        'REQUEST_ID': 'count',  # Adjust column name if different\n        'LATENCY_MS': 'mean',\n        'CORTEX_ANALYST_CREDITS': 'sum'\n    }).rename(columns={\n        'REQUEST_ID': 'queries_count',\n        'LATENCY_MS': 'avg_latency_ms',\n        'CORTEX_ANALYST_CREDITS': 'total_credits'\n    }).round(2).reset_index()\n    \n    # Add percentage of user's queries per model\n    user_totals = user_model_activity.groupby('USER_NAME')['queries_count'].sum()\n    user_model_activity['percentage_of_user_queries'] = (\n        user_model_activity.apply(\n            lambda row: round((row['queries_count'] / user_totals[row['USER_NAME']]) * 100, 2),\n            axis=1\n        )\n    )\n    \n    # Sort by user name and query count\n    user_model_activity = user_model_activity.sort_values(\n        ['USER_NAME', 'queries_count'], \n        ascending=[True, False]\n    ).reset_index(drop=True)\n    \n    return user_model_activity\n\n\ndef user_activity_by_semantic_model(df):\n    \"\"\"\n    Provides user activity analysis by semantic model.\n    Returns a DataFrame with user activity broken down by semantic model.\n    \"\"\"\n    import pandas as pd\n    \n    # User activity by semantic model\n    user_model_activity = df.groupby(['USER_NAME', 'SEMANTIC_MODEL_NAME']).agg({\n        'REQUEST_ID': 'count',  # Adjust column name if different\n        'LATENCY_MS': 'mean',\n        'CORTEX_ANALYST_CREDITS': 'sum'\n    }).rename(columns={\n        'REQUEST_ID': 'queries_count',\n        'LATENCY_MS': 'avg_latency_ms',\n        'CORTEX_ANALYST_CREDITS': 'total_credits'\n    }).round(2).reset_index()\n    \n    # Add percentage of user's queries per model\n    user_totals = user_model_activity.groupby('USER_NAME')['queries_count'].sum()\n    user_model_activity['percentage_of_user_queries'] = (\n        user_model_activity.apply(\n            lambda row: round((row['queries_count'] / user_totals[row['USER_NAME']]) * 100, 2),\n            axis=1\n        )\n    )\n    \n    # Sort by user name and query count\n    user_model_activity = user_model_activity.sort_values(\n        ['USER_NAME', 'queries_count'], \n        ascending=[True, False]\n    ).reset_index(drop=True)\n    \n    return user_model_activity\n\n\ndef semantic_model_usage_summary(df):\n    \"\"\"\n    Provides overall semantic model usage summary.\n    Returns a DataFrame with usage statistics per semantic model.\n    \"\"\"\n    model_usage = df.groupby('SEMANTIC_MODEL_NAME').agg({\n        'REQUEST_ID': 'count',  # Adjust column name if different\n        'USER_NAME': 'nunique',\n        'LATENCY_MS': 'mean',\n        'CORTEX_ANALYST_CREDITS': 'sum'\n    }).rename(columns={\n        'REQUEST_ID': 'total_queries',\n        'USER_NAME': 'unique_users',\n        'LATENCY_MS': 'avg_latency_ms',\n        'CORTEX_ANALYST_CREDITS': 'total_cortex_analyst_credits'\n    }).round(2).reset_index()\n    \n    # Add percentage of total queries\n    model_usage['percentage'] = round(\n        (model_usage['total_queries'] / model_usage['total_queries'].sum()) * 100, 2\n    )\n    \n    # Sort by total queries descending\n    model_usage = model_usage.sort_values('total_queries', ascending=False).reset_index(drop=True)\n    \n    return model_usage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47cfd909-88a6-468d-b6be-1010756d8ff7",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "print(\"TIMESTAMP column sample:\")\nprint(df_agg['TIMESTAMP'].head())\nprint(\"\\nTIMESTAMP column dtype:\")\nprint(df_agg['TIMESTAMP'].dtype)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61032e84-c802-4b78-b2f4-a24ed2787e64",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "df_copy = df_agg.copy()\n\ndf_copy['TIMESTAMP']\n    \n# Since TIMESTAMP is already datetime64[us], just extract the date\n# df_copy['date'] = df_copy['TIMESTAMP'].dt.date\n\n# daily_model_usage = df_copy.groupby(['date', 'SEMANTIC_MODEL_NAME']).agg({\n#     'REQUEST_ID': 'count',  # Adjust column name if different\n#     'USER_NAME': 'nunique'\n# }).rename(columns={\n#     'REQUEST_ID': 'queries_count',\n#     'USER_NAME': 'unique_users'\n# }).reset_index()\n\n# # Sort by date and semantic model\n# daily_model_usage = daily_model_usage.sort_values(\n#     ['date', 'SEMANTIC_MODEL_NAME']\n# ).reset_index(drop=True)\n    \n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e946b8c-a679-46fa-87f6-b30dc8807251",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# Get user activity by semantic model\nuser_activity_df = user_activity_by_semantic_model(df_agg)\nprint(user_activity_df)\n\n# Get daily usage by semantic model\ndaily_usage_df = daily_usage_by_semantic_model(df_agg)\nprint(daily_usage_df)\n\n# Get semantic model usage summary\nmodel_summary_df = semantic_model_usage_summary(df_agg)\nprint(model_summary_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28812168-ca34-44f3-83a4-115dccc9e5d7",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "user_activity_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8df8ed74-7048-4e12-90e6-de5b986487a0",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "def create_cortex_analyst_query_history(session, cortex_analyst_df, sf_intelligence_table=\"snowflake_intelligence.public.sf_intelligence_query_history\"):\n    \"\"\"\n    Creates joined query history by merging Snowflake Intelligence query history \n    with Cortex Analyst logs on generated SQL.\n    \n    Parameters\n    ----------\n    session : snowflake.snowpark.Session\n        Active Snowpark session\n    cortex_analyst_df : pandas.DataFrame\n        DataFrame containing Cortex Analyst logs with GENERATED_SQL column\n    sf_intelligence_table : str, optional\n        Fully qualified name of the Snowflake Intelligence query history table\n    \n    Returns\n    -------\n    pandas.DataFrame\n        Joined DataFrame with additional computed columns\n    \"\"\"\n    \n    # Load Snowflake Intelligence query history\n    sfi_query_history = session.table(sf_intelligence_table)\n    pd_sfi_query_history = sfi_query_history.to_pandas()\n    \n    # Set indexes for joining\n    pd_sfi_query_history_indexed = pd_sfi_query_history.set_index(\"CLEANED_QUERY_TEXT\")\n    cortex_analyst_indexed = cortex_analyst_df.set_index(\"GENERATED_SQL\")\n    \n    # Join on generated SQL (left index = cleaned_query_text, right index = generated_sql)\n    ca_query_history = pd.merge(\n        pd_sfi_query_history_indexed, \n        cortex_analyst_indexed, \n        left_index=True, \n        right_index=True,  # You can change to 'left', 'right', or 'outer' as needed\n    )\n    \n    # Add computed columns\n    ca_query_history['TOTAL_TIME'] = (\n        ca_query_history[\"TOTAL_ELAPSED_TIME\"] + ca_query_history[\"LATENCY_MS\"]\n    )\n    \n    ca_query_history['TOTAL_CREDITS_WH_AND_CA'] = (\n        ca_query_history[\"CREDITS_ATTRIBUTED_COMPUTE\"] + ca_query_history[\"CORTEX_ANALYST_CREDITS\"]\n    )\n    \n    # Reset index to make it a regular DataFrame\n    ca_query_history = ca_query_history.reset_index()\n    \n    return ca_query_history",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93c960a2-d530-4777-81c1-c60e9db3ca01",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e84e6c11-9bc4-40e9-a61e-791d2b8b4d1f",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "glued_df = create_cortex_analyst_query_history(session, df_agg, \"snowflake_intelligence.public.sf_intelligence_query_history\")\nglued_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73940a8c-c07c-409d-b025-1389f28e9473",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "# df_agg\n\n\nsfi_query_history = session.table(\"snowflake_intelligence.public.sf_intelligence_query_history\")\npd_sfi_query_history = sfi_query_history.to_pandas()\npd_sfi_query_history.set_index(\"CLEANED_QUERY_TEXT\")\ndf_agg.set_index(\"GENERATED_SQL\")\n# pd_sfi_query_history\n# ##joining on generated SQL\nca_query_history = pd.merge(pd_sfi_query_history, df_agg, left_index=True, right_index=True)\n# ca_query_history['TOTAL_TIME'] = ca_query_history[\"TOTAL_ELAPSED_TIME\"] + ca_query_history[\"LATENCY_MS\"]\n# ca_query_history['TOTAL_CREDITS_WH_AND_CA'] = ca_query_history[\"CREDITS_ATTRIBUTED_COMPUTE\"] + ca_query_history[\"CORTEX_ANALYST_CREDITS\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fff148bb-1177-4967-9a01-fce59e2fd2d0",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "ca_query_history['TOTAL_TIME'] = ca_query_history[\"TOTAL_ELAPSED_TIME\"] + ca_query_history[\"LATENCY_MS\"]\nca_query_history['TOTAL_CREDITS_WH_AND_CA'] = ca_query_history[\"CREDITS_ATTRIBUTED_COMPUTE\"] + ca_query_history[\"CORTEX_ANALYST_CREDITS\"]\n\ntotal_cost_by_semantic_model = ca_query_history[['SEMANTIC_MODEL_NAME','TOTAL_CREDITS_WH_AND_CA']].groupby(['SEMANTIC_MODEL_NAME']).sum(['TOTAL_CREDITS_WH_AND_CA'])\ntotal_cost_by_semantic_model",
   "execution_count": null
  }
 ]
}