{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Snowflake AI Cost Toolkit - Setup and Data Population\n",
        "\n",
        "This notebook sets up the complete Snowflake AI Cost Toolkit including:\n",
        "1. Database schema creation (tables, views, procedures)\n",
        "2. Data population from Cortex Analyst logs\n",
        "3. Budget alerting system setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries and Setup Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "# Import utility functions\n",
        "from utils import (\n",
        "    fetch_semantic_model_paths,\n",
        "    get_cortex_analyst_logs,\n",
        "    write_logs_to_table,\n",
        "    create_sf_intelligence_query_history\n",
        ")\n",
        "\n",
        "# Get active session\n",
        "session = get_active_session()\n",
        "print(\"‚úÖ Session initialized successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Database and Schema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create database and schema\n",
        "session.sql(\"CREATE DATABASE IF NOT EXISTS CORTEX_ANALYTICS\").collect()\n",
        "session.sql(\"USE DATABASE CORTEX_ANALYTICS\").collect()\n",
        "session.sql(\"CREATE SCHEMA IF NOT EXISTS PUBLIC\").collect()\n",
        "session.sql(\"USE SCHEMA PUBLIC\").collect()\n",
        "\n",
        "print(\"‚úÖ Database and schema created/selected: CORTEX_ANALYTICS.PUBLIC\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Core Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Cortex Analyst Logs table\n",
        "create_cortex_logs_table = \"\"\"\n",
        "CREATE OR REPLACE TABLE CORTEX_ANALYST_LOGS (\n",
        "    TIMESTAMP                TIMESTAMP_NTZ,\n",
        "    REQUEST_ID               STRING,\n",
        "    SEMANTIC_MODEL_NAME      STRING,\n",
        "    TABLES_REFERENCED        STRING,\n",
        "    USER_NAME                STRING,\n",
        "    SOURCE                   STRING,\n",
        "    FEEDBACK                 STRING,\n",
        "    RESPONSE_STATUS_CODE     INTEGER,\n",
        "    USER_QUESTION            STRING,\n",
        "    LATENCY_MS               NUMBER,\n",
        "    GENERATED_SQL            STRING,\n",
        "    ORCHESTRATION_PATH       STRING,\n",
        "    QUESTION_CATEGORY        STRING,\n",
        "    VERIFIED_QUERY_NAME      STRING,\n",
        "    VERIFIED_QUERY_QUESTION  STRING,\n",
        "    QUERY_TYPE               STRING,\n",
        "    CORTEX_ANALYST_CREDITS   FLOAT\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(create_cortex_logs_table).collect()\n",
        "print(\"‚úÖ CORTEX_ANALYST_LOGS table created\")\n",
        "\n",
        "# Create the query history table using the utility function\n",
        "target_table = \"CORTEX_ANALYTICS.PUBLIC.SF_INTELLIGENCE_QUERY_HISTORY\"\n",
        "\n",
        "try:\n",
        "    create_sf_intelligence_query_history(session, target_table)\n",
        "    print(f\"‚úÖ {target_table} created successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Warning: Could not create query history table: {e}\")\n",
        "    print(\"This may be due to insufficient permissions on ACCOUNT_USAGE views\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Fetch Semantic Model Paths and Populate Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch semantic model paths from all agents\n",
        "try:\n",
        "    df_results = fetch_semantic_model_paths(session)\n",
        "    print(f\"‚úÖ Found {len(df_results)} semantic model configurations\")\n",
        "    display(df_results)\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Warning: Could not fetch semantic model paths: {e}\")\n",
        "    print(\"This may be because no Cortex Agents are configured in your account\")\n",
        "    df_results = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Populate Cortex Analyst Logs - following the pattern from your example\n",
        "if not df_results.empty and 'semantic_model_file' in df_results.columns:\n",
        "    semantic_model_files = df_results['semantic_model_file'].dropna().unique().tolist()\n",
        "    print(f\"üìÑ Processing {len(semantic_model_files)} unique semantic model files\")\n",
        "    \n",
        "    for file in semantic_model_files:\n",
        "        if file != None:\n",
        "            print(f\"\\nüìä Processing: {file}\")\n",
        "            \n",
        "            try:\n",
        "                # Get logs for this semantic model\n",
        "                df = get_cortex_analyst_logs(session, file)\n",
        "                \n",
        "                if not df.empty:\n",
        "                    print(f\"   ‚úÖ Retrieved {len(df)} log entries\")\n",
        "                    \n",
        "                    # Write to table using pandas write\n",
        "                    session.write_pandas(\n",
        "                        df,\n",
        "                        table_name=\"CORTEX_ANALYST_LOGS\",\n",
        "                        auto_create_table=False,\n",
        "                        overwrite=False  # Append to existing data\n",
        "                    )\n",
        "                    print(f\"   ‚úÖ Data written to CORTEX_ANALYST_LOGS table\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  No log entries found for this semantic model\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Error processing {file}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    print(\"\\nüéâ Completed processing all semantic model files\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No semantic model files found to process\")\n",
        "    print(\"Please ensure you have Cortex Agents configured with semantic models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Verify Data Population\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check how many records were loaded\n",
        "record_count = session.sql(\"SELECT COUNT(*) as total_records FROM CORTEX_ANALYST_LOGS\").collect()[0]['TOTAL_RECORDS']\n",
        "print(f\"üìä Total records in CORTEX_ANALYST_LOGS table: {record_count:,}\")\n",
        "\n",
        "if record_count > 0:\n",
        "    # Show sample data\n",
        "    sample_data = session.sql(\"\"\"\n",
        "        SELECT \n",
        "            semantic_model_name,\n",
        "            COUNT(*) as log_count,\n",
        "            MIN(timestamp) as earliest_log,\n",
        "            MAX(timestamp) as latest_log\n",
        "        FROM CORTEX_ANALYST_LOGS \n",
        "        GROUP BY semantic_model_name \n",
        "        ORDER BY log_count DESC\n",
        "    \"\"\").to_pandas()\n",
        "    \n",
        "    print(\"\\nüìà Summary by Semantic Model:\")\n",
        "    display(sample_data)\n",
        "    \n",
        "    # Show query type breakdown\n",
        "    query_types = session.sql(\"\"\"\n",
        "        SELECT \n",
        "            query_type,\n",
        "            COUNT(*) as count,\n",
        "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
        "        FROM CORTEX_ANALYST_LOGS \n",
        "        GROUP BY query_type\n",
        "        ORDER BY count DESC\n",
        "    \"\"\").to_pandas()\n",
        "    \n",
        "    print(\"\\nüîç Query Type Breakdown:\")\n",
        "    display(query_types)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No data was loaded. This could be because:\")\n",
        "    print(\"   ‚Ä¢ No Cortex Agents are configured\")\n",
        "    print(\"   ‚Ä¢ No queries have been made to the agents yet\")\n",
        "    print(\"   ‚Ä¢ Semantic model files are not accessible\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"üéâ SNOWFLAKE AI COST TOOLKIT SETUP COMPLETE!\\n\")\n",
        "print(\"‚úÖ Database objects created:\")\n",
        "print(\"   ‚Ä¢ CORTEX_ANALYTICS database and PUBLIC schema\")\n",
        "print(\"   ‚Ä¢ CORTEX_ANALYST_LOGS table\")\n",
        "print(\"   ‚Ä¢ SF_INTELLIGENCE_QUERY_HISTORY table\")\n",
        "\n",
        "record_count = session.sql(\"SELECT COUNT(*) as count FROM CORTEX_ANALYST_LOGS\").collect()[0]['COUNT']\n",
        "print(f\"\\nüìä Data populated: {record_count:,} Cortex Analyst log records\")\n",
        "\n",
        "print(\"\\nüöÄ Next steps:\")\n",
        "print(\"   1. Run the remaining setup.sql script for views and procedures\")\n",
        "print(\"   2. Deploy the Streamlit dashboard for interactive analysis\")\n",
        "print(\"   3. Set up notification integrations for budget alerts\")\n",
        "print(\"   4. Configure automated tasks for regular monitoring\")\n",
        "\n",
        "print(\"\\nüìö Available files:\")\n",
        "print(\"   ‚Ä¢ setup.sql - Contains views, procedures, and budget alerting\")\n",
        "print(\"   ‚Ä¢ budget_alerting_examples.sql - Detailed alerting examples\")\n",
        "print(\"   ‚Ä¢ streamlit_app.py - Interactive dashboard\")\n",
        "print(\"   ‚Ä¢ utils.py - All utility functions used in this notebook\")\n",
        "\n",
        "print(\"\\n‚ú® Your Cortex Analyst data is now ready for analysis!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
